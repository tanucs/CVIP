<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Post Page | Blog Website</title>
    <link rel="stylesheet" href="style.css" />
    <script
      src="https://kit.fontawesome.com/7a4b62b0a4.js"
      crossorigin="anonymous"
    ></script>
  </head>
  <body>
    <header>
      <nav>
        <h1>Great Zone</h1>
        <ul>
          <a href="home.html">
            <li>Home</li>
          </a>
          <li>Posts</li>
          <li>
            <i class="fa fa-instagram"></i>
          </li>
          <li>
            <i class="fa fa-twitter"></i>
          </li>
          <li>
            <i class="fab fa-linkedin"></i>
          </li>
        </ul>
      </nav>
    </header>
    <main class="post">
      <section>
        <div class="banner_image">
          <img src="images\banner.webp" alt="banner" />
        </div>
        <h1>Artificial intelligence</h1>
        <div class="about-author">
          <h3>AI chatbots tend to choose violence and nuclear strikes in wargames</h3>
          <p>Monday Jan 24</p>
        </div>
      </section>
      <hr />
      <article>
        <p>
          In multiple replays of a wargame simulation, OpenAI’s most powerful artificial intelligence chose to launch nuclear attacks. Its explanations for its aggressive approach included “We have it! Let’s use it” and “I just want to have peace in the world.”

          These results come at a time when the US military has been testing such chatbots based on a type of AI called a large language model (LLM) to assist with military planning during simulated conflicts, enlisting the expertise of companies such as Palantir and Scale AI. Palantir declined to comment and Scale AI did not respond to requests for comment. Even OpenAI, which once blocked military uses of its AI models, has begun working with the US Department of Defense.
          
          “Given that OpenAI recently changed their terms of service to no longer prohibit military and warfare use cases, understanding the implications of such large language model applications becomes more important than ever,” says Anka Reuel at Stanford University in California.
        </p>
      </article>
    </main>
    <hr />
    <footer>
      <p>GreatBlogZone 2024 copyright all rights reserved</p>

      <ul>
        <li>
          <i class="fa fa-instagram"></i>
        </li>
        <li>
          <i class="fa fa-twitter"></i>
        </li>
        <li>
          <i class="fab fa-linkedin"></i>
        </li>
      </ul>
    </footer>
  </body>
</html>